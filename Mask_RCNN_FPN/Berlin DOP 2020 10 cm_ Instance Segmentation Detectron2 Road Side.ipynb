{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Berlin DOP 2020 10 cm: Instance Segmentation Detectron2 Road Side.ipynb","provenance":[{"file_id":"191H7yU_ygeWiukZ73FMUVxpb2DJ-F0GF","timestamp":1638810295639},{"file_id":"1r8LtFRqGYfnD9E4ebEyQ0i_910jozOOZ","timestamp":1635170647271},{"file_id":"1PpkTjA9uKWs8TSaEFU56RvriLnrnvCdl","timestamp":1634411615559},{"file_id":"1y55m4yjmRcJlSHfK19HLEXzEhlqarce1","timestamp":1630963543496},{"file_id":"https://github.com/Bashinim/Parking-Lot-Detection/blob/main/Detectron2/Berlin%20DOP%202020%2010%20cm%3A%20Instance%20Segmentation%20Detectron2.ipynb","timestamp":1626205849201}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dFiC7uWxOhA7"},"source":["# Instance Segmentation with Berlin DOP, 10 cm resolution. The annotations are in COCO format\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vi4X2SveN8L0","executionInfo":{"status":"ok","timestamp":1643481952684,"user_tz":-60,"elapsed":1945,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}},"outputId":"1e2b0c27-cff9-43f4-809e-f0469adebe3a"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"miCoOsXkx1Zy","executionInfo":{"status":"ok","timestamp":1643481291167,"user_tz":-60,"elapsed":418,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}},"outputId":"76a93222-c1a8-43d5-c539-724568724025"},"source":["!nvidia-RAM\n"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: nvidia-RAM: command not found\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ViPk8dCwNwJ","executionInfo":{"status":"ok","timestamp":1643481291167,"user_tz":-60,"elapsed":11,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}},"outputId":"b4944db3-6449-48c9-c134-0aafa91704bc"},"source":["!cat /proc/meminfo"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["MemTotal:       26696420 kB\n","MemFree:         4799444 kB\n","MemAvailable:   25084896 kB\n","Buffers:          145148 kB\n","Cached:         19883140 kB\n","SwapCached:            0 kB\n","Active:          2475016 kB\n","Inactive:       18678476 kB\n","Active(anon):     954296 kB\n","Inactive(anon):      508 kB\n","Active(file):    1520720 kB\n","Inactive(file): 18677968 kB\n","Unevictable:           0 kB\n","Mlocked:               0 kB\n","SwapTotal:             0 kB\n","SwapFree:              0 kB\n","Dirty:               468 kB\n","Writeback:            12 kB\n","AnonPages:       1125268 kB\n","Mapped:          1040328 kB\n","Shmem:              1204 kB\n","KReclaimable:     504252 kB\n","Slab:             575456 kB\n","SReclaimable:     504252 kB\n","SUnreclaim:        71204 kB\n","KernelStack:        6832 kB\n","PageTables:        14348 kB\n","NFS_Unstable:          0 kB\n","Bounce:                0 kB\n","WritebackTmp:          0 kB\n","CommitLimit:    13348208 kB\n","Committed_AS:    4752984 kB\n","VmallocTotal:   34359738367 kB\n","VmallocUsed:       49784 kB\n","VmallocChunk:          0 kB\n","Percpu:             2896 kB\n","AnonHugePages:         0 kB\n","ShmemHugePages:        0 kB\n","ShmemPmdMapped:        0 kB\n","FileHugePages:         0 kB\n","FilePmdMapped:         0 kB\n","CmaTotal:              0 kB\n","CmaFree:               0 kB\n","HugePages_Total:       0\n","HugePages_Free:        0\n","HugePages_Rsvd:        0\n","HugePages_Surp:        0\n","Hugepagesize:       2048 kB\n","Hugetlb:               0 kB\n","DirectMap4k:      181056 kB\n","DirectMap2M:     6107136 kB\n","DirectMap1G:    23068672 kB\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBD4PAvtTBL4","executionInfo":{"status":"ok","timestamp":1643481956816,"user_tz":-60,"elapsed":702,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}},"outputId":"e9aa3444-68f0-435a-d64f-55e516d7667b"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Jan 29 18:45:55 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ijSWFCGfzFfU","executionInfo":{"status":"ok","timestamp":1643481959186,"user_tz":-60,"elapsed":791,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}},"outputId":"7a3e32b9-066f-448f-8925-a1031825f623"},"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 27.3 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"code","metadata":{"id":"CMcIwYbnOtpE","executionInfo":{"status":"ok","timestamp":1643481291169,"user_tz":-60,"elapsed":7,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}}},"source":["# install detectron2: (Colab has CUDA 10.1 + torch 1.8)\n","# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n","#import torch\n","#assert torch.__version__.startswith(\"1.8\")   # need to manually install torch 1.8 if Colab changes its default version\n","# !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n","#!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\n","# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R7L0fpBqOvXL"},"source":["## Get data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-x5aZROl_ZzK","executionInfo":{"status":"ok","timestamp":1643481291169,"user_tz":-60,"elapsed":7,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}},"outputId":"532fe796-27c6-4f85-f030-965f45d71705"},"source":["# check CUDA version\n","!nvcc --version"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Mon_Oct_12_20:09:46_PDT_2020\n","Cuda compilation tools, release 11.1, V11.1.105\n","Build cuda_11.1.TC455_06.29190527_0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B3ZQaRy1_c_Z","executionInfo":{"status":"ok","timestamp":1643481291170,"user_tz":-60,"elapsed":6,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}},"outputId":"93c8f0ff-f346-487e-be86-41a05b65a6a4"},"source":["import torch\n","print(torch.__version__, torch.cuda.is_available())"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["1.10.0+cu111 True\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zc8RQOkv-Fu-","executionInfo":{"status":"ok","timestamp":1643481291590,"user_tz":-60,"elapsed":425,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}},"outputId":"dfb829a9-a816-4028-ffaf-1210c3386648"},"source":["!ls -d /usr/local/cuda-*"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/cuda-10.0  /usr/local/cuda-11    /usr/local/cuda-11.1\n","/usr/local/cuda-10.1  /usr/local/cuda-11.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"slwl_44F-Kju","executionInfo":{"status":"ok","timestamp":1643481294505,"user_tz":-60,"elapsed":2918,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}},"outputId":"8be9dbb6-4802-41e6-f9a6-59d1ce0f0820"},"source":["!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Requirement already satisfied: torch==1.9.0+cu111 in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n","Requirement already satisfied: torchvision==0.10.0+cu111 in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (3.10.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.19.5)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sBlQ9oqq-oed","executionInfo":{"status":"ok","timestamp":1643481968169,"user_tz":-60,"elapsed":3740,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}},"outputId":"d02d80eb-1139-4adb-87ca-65c1c48fe613"},"source":["!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.9/index.html"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.9/index.html\n","Requirement already satisfied: detectron2 in /usr/local/lib/python3.7/dist-packages (0.6+cu111)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: black==21.4b2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (21.4b2)\n","Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.5.post20220119)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2) (3.2.2)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.8.9)\n","Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.9)\n","Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.1.1)\n","Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.1)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.0.4)\n","Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.8)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.7.0)\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (7.1.2)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2) (4.62.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.16.0)\n","Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.4.3)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.4.4)\n","Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.10.2)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (3.10.0.2)\n","Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (7.1.2)\n","Requirement already satisfied: typed-ast>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.5.2)\n","Requirement already satisfied: pathspec<1,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.9.0)\n","Requirement already satisfied: regex>=2020.1.8 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (2022.1.18)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (1.19.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (6.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (5.4.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (4.8)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2) (2.3.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.3.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (3.0.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2) (1.15.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core>=1.1->detectron2) (3.7.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.35.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.17.3)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.37.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (57.4.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.3.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.8.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.6.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.43.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (4.10.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.1)\n"]}]},{"cell_type":"code","metadata":{"id":"S-sSjm1MOwMv","executionInfo":{"status":"ok","timestamp":1643481975248,"user_tz":-60,"elapsed":1540,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}}},"source":["import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import cv2\n","import random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog\n","from detectron2.data.catalog import DatasetCatalog"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nTDE9hMiQvLd"},"source":["Importing data"]},{"cell_type":"code","metadata":{"id":"liqL7hxSQi4Z","executionInfo":{"status":"ok","timestamp":1643481979479,"user_tz":-60,"elapsed":416,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}}},"source":["from detectron2.data.datasets import register_coco_instances\n","register_coco_instances(\"my_dataset_train\", {}, \"/content/drive/MyDrive/Berlin DOP 2020 10cm SidesofRoad/Train_annotations.json\", \"/content/drive/MyDrive/Berlin DOP 2020 10cm SidesofRoad/Train\")\n","register_coco_instances(\"my_dataset_valid\", {}, \"/content/drive/MyDrive/Berlin DOP 2020 10cm SidesofRoad/Valid_annotations.json\", \"/content/drive/MyDrive/Berlin DOP 2020 10cm SidesofRoad/Valid\")\n","register_coco_instances(\"my_dataset_test\", {}, \"\", \"/content/drive/MyDrive/Berlin DOP 2020 10cm SidesofRoad/Test\")"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_d3Q5v4pHLz7"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"lO2z7zp-Pjzt"},"source":["## Register data-set\n","\n","In order to use a dataset with Detectron2 we need to register it. For more information check out the official documentation."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1VtgXDqWboA6igIxDumJZ9g6MIgTVqUjI"},"id":"D0eg3COlajty","executionInfo":{"status":"ok","timestamp":1643482010221,"user_tz":-60,"elapsed":24749,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}},"outputId":"5ced6e46-5989-403d-b159-c6dd9b76335c"},"source":["#visualize training data\n","my_dataset_train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n","dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n","\n","import random\n","from detectron2.utils.visualizer import Visualizer\n","\n","for d in random.sample(dataset_dicts, 3):\n","    img = cv2.imread(d[\"file_name\"])\n","    visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=1)\n","    vis = visualizer.draw_dataset_dict(d)\n","    cv2_imshow(vis.get_image()[:, :, ::-1])"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"Q7EmsuFlqgL5"},"source":["## Train model\n","\n","Now, let's fine-tune a pretrained FasterRCNN instance segmentation model on the microcontroller data-set."]},{"cell_type":"code","metadata":{"id":"i7HEglSnZJ9i","executionInfo":{"status":"aborted","timestamp":1643481297990,"user_tz":-60,"elapsed":16,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}}},"source":["%%javascript\n","function ClickConnect(){\n","console.log(\"Working\");\n","document.querySelector(\"colab-toolbar-button#connect\").click()\n","}setInterval(ClickConnect,60000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tB7w2PrWaHFz","executionInfo":{"status":"ok","timestamp":1643482241118,"user_tz":-60,"elapsed":230900,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}},"outputId":"e670aad2-b40f-4814-e01e-1d393608051d"},"source":["from detectron2.engine import DefaultTrainer\n","from detectron2.config import get_cfg\n","import os\n","\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n","cfg.DATASETS.TEST = ()\n","cfg.DATALOADER.NUM_WORKERS = 2\n","# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n","cfg.SOLVER.IMS_PER_BATCH = 2\n","cfg.SOLVER.BASE_LR = 0.0025\n","cfg.SOLVER.MAX_ITER = 700\n","cfg.SOLVER.STEPS = []        # do not decay learning rate\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = DefaultTrainer(cfg) \n","trainer.resume_or_load(resume=False)\n","trainer.train()\n","\n"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32m[01/29 18:46:39 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n","    )\n","    (mask_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (mask_head): MaskRCNNConvUpsampleHead(\n","      (mask_fcn1): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn2): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn3): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn4): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (deconv_relu): ReLU()\n","      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/29 18:46:39 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[01/29 18:46:39 d2.data.datasets.coco]: \u001b[0mLoaded 127 images in COCO format from /content/drive/MyDrive/Berlin DOP 2020 10cm SidesofRoad/Train_annotations.json\n","\u001b[32m[01/29 18:46:39 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 127 images left.\n","\u001b[32m[01/29 18:46:39 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n","\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n","|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n","|  Ocluded   | 297          |  Parking   | 62           |  Possible  | 53           |\n","|            |              |            |              |            |              |\n","|   total    | 412          |            |              |            |              |\u001b[0m\n","\u001b[32m[01/29 18:46:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[01/29 18:46:39 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[01/29 18:46:39 d2.data.common]: \u001b[0mSerializing 127 elements to byte tensors and concatenating them all ...\n","\u001b[32m[01/29 18:46:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.10 MiB\n"]},{"output_type":"stream","name":"stderr","text":["model_final_f10217.pkl: 178MB [00:08, 20.0MB/s]                           \n","Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n","Some model parameters or buffers are not found in the checkpoint:\n","\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32m[01/29 18:46:54 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n","To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n","  return torch.floor_divide(self, other)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32m[01/29 18:47:11 d2.utils.events]: \u001b[0m eta: 0:08:47  iter: 19  total_loss: 1.955  loss_cls: 0.8788  loss_box_reg: 0.1724  loss_mask: 0.6841  loss_rpn_cls: 0.1325  loss_rpn_loc: 0.0387  time: 0.8021  data_time: 0.5741  lr: 7.0289e-05  max_mem: 1862M\n","\u001b[32m[01/29 18:47:26 d2.utils.events]: \u001b[0m eta: 0:08:32  iter: 39  total_loss: 1.338  loss_cls: 0.3381  loss_box_reg: 0.2016  loss_mask: 0.6334  loss_rpn_cls: 0.07513  loss_rpn_loc: 0.04391  time: 0.7883  data_time: 0.5293  lr: 0.00014165  max_mem: 1927M\n","\u001b[32m[01/29 18:47:43 d2.utils.events]: \u001b[0m eta: 0:08:13  iter: 59  total_loss: 1.178  loss_cls: 0.2509  loss_box_reg: 0.2306  loss_mask: 0.5134  loss_rpn_cls: 0.0614  loss_rpn_loc: 0.06515  time: 0.8081  data_time: 0.5882  lr: 0.000213  max_mem: 1927M\n","\u001b[32m[01/29 18:47:49 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 79  total_loss: 1.054  loss_cls: 0.1946  loss_box_reg: 0.1913  loss_mask: 0.4885  loss_rpn_cls: 0.06147  loss_rpn_loc: 0.05188  time: 0.6830  data_time: 0.0712  lr: 0.00028436  max_mem: 1927M\n","\u001b[32m[01/29 18:47:55 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 99  total_loss: 1.089  loss_cls: 0.2079  loss_box_reg: 0.1975  loss_mask: 0.4682  loss_rpn_cls: 0.04761  loss_rpn_loc: 0.06055  time: 0.6002  data_time: 0.0049  lr: 0.00035572  max_mem: 2153M\n","\u001b[32m[01/29 18:48:00 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 119  total_loss: 1.067  loss_cls: 0.2257  loss_box_reg: 0.2666  loss_mask: 0.4229  loss_rpn_cls: 0.04288  loss_rpn_loc: 0.02615  time: 0.5438  data_time: 0.0051  lr: 0.00042708  max_mem: 2153M\n","\u001b[32m[01/29 18:48:06 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 139  total_loss: 0.9395  loss_cls: 0.1833  loss_box_reg: 0.2184  loss_mask: 0.3844  loss_rpn_cls: 0.03681  loss_rpn_loc: 0.04921  time: 0.5043  data_time: 0.0049  lr: 0.00049843  max_mem: 2153M\n","\u001b[32m[01/29 18:48:11 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 159  total_loss: 0.9508  loss_cls: 0.1888  loss_box_reg: 0.2164  loss_mask: 0.4189  loss_rpn_cls: 0.03038  loss_rpn_loc: 0.0282  time: 0.4739  data_time: 0.0053  lr: 0.00056979  max_mem: 2301M\n","\u001b[32m[01/29 18:48:16 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 179  total_loss: 0.9214  loss_cls: 0.2165  loss_box_reg: 0.2692  loss_mask: 0.3495  loss_rpn_cls: 0.03262  loss_rpn_loc: 0.05862  time: 0.4509  data_time: 0.0053  lr: 0.00064115  max_mem: 2301M\n","\u001b[32m[01/29 18:48:22 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 199  total_loss: 0.9165  loss_cls: 0.2009  loss_box_reg: 0.2691  loss_mask: 0.3257  loss_rpn_cls: 0.02902  loss_rpn_loc: 0.03198  time: 0.4328  data_time: 0.0051  lr: 0.0007125  max_mem: 2301M\n","\u001b[32m[01/29 18:48:27 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 219  total_loss: 0.771  loss_cls: 0.1654  loss_box_reg: 0.2309  loss_mask: 0.2886  loss_rpn_cls: 0.01987  loss_rpn_loc: 0.03309  time: 0.4178  data_time: 0.0051  lr: 0.00078386  max_mem: 2365M\n","\u001b[32m[01/29 18:48:33 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 239  total_loss: 0.7936  loss_cls: 0.1824  loss_box_reg: 0.2395  loss_mask: 0.2688  loss_rpn_cls: 0.02188  loss_rpn_loc: 0.03885  time: 0.4057  data_time: 0.0050  lr: 0.00085522  max_mem: 2365M\n","\u001b[32m[01/29 18:48:38 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 259  total_loss: 0.8332  loss_cls: 0.1686  loss_box_reg: 0.1844  loss_mask: 0.3114  loss_rpn_cls: 0.03465  loss_rpn_loc: 0.06567  time: 0.3955  data_time: 0.0055  lr: 0.00092658  max_mem: 2365M\n","\u001b[32m[01/29 18:48:44 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 279  total_loss: 0.6509  loss_cls: 0.1402  loss_box_reg: 0.1958  loss_mask: 0.2708  loss_rpn_cls: 0.01661  loss_rpn_loc: 0.02157  time: 0.3868  data_time: 0.0053  lr: 0.00099793  max_mem: 2365M\n","\u001b[32m[01/29 18:48:50 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 299  total_loss: 0.7584  loss_cls: 0.1631  loss_box_reg: 0.2104  loss_mask: 0.2527  loss_rpn_cls: 0.02657  loss_rpn_loc: 0.05039  time: 0.3805  data_time: 0.0065  lr: 0.0010693  max_mem: 2365M\n","\u001b[32m[01/29 18:48:55 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 319  total_loss: 0.7648  loss_cls: 0.1752  loss_box_reg: 0.2292  loss_mask: 0.2464  loss_rpn_cls: 0.02376  loss_rpn_loc: 0.03322  time: 0.3739  data_time: 0.0052  lr: 0.0011406  max_mem: 2365M\n","\u001b[32m[01/29 18:49:01 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 339  total_loss: 0.6613  loss_cls: 0.1437  loss_box_reg: 0.1849  loss_mask: 0.2222  loss_rpn_cls: 0.01173  loss_rpn_loc: 0.04009  time: 0.3682  data_time: 0.0052  lr: 0.001212  max_mem: 2365M\n","\u001b[32m[01/29 18:49:06 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 359  total_loss: 0.6101  loss_cls: 0.1094  loss_box_reg: 0.134  loss_mask: 0.1933  loss_rpn_cls: 0.01407  loss_rpn_loc: 0.02587  time: 0.3625  data_time: 0.0053  lr: 0.0012834  max_mem: 2365M\n","\u001b[32m[01/29 18:49:12 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 379  total_loss: 0.6392  loss_cls: 0.145  loss_box_reg: 0.1631  loss_mask: 0.2439  loss_rpn_cls: 0.02029  loss_rpn_loc: 0.04908  time: 0.3575  data_time: 0.0052  lr: 0.0013547  max_mem: 2365M\n","\u001b[32m[01/29 18:49:17 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 399  total_loss: 0.6453  loss_cls: 0.131  loss_box_reg: 0.1441  loss_mask: 0.2203  loss_rpn_cls: 0.01565  loss_rpn_loc: 0.02791  time: 0.3533  data_time: 0.0054  lr: 0.0014261  max_mem: 2365M\n","\u001b[32m[01/29 18:49:23 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 419  total_loss: 0.631  loss_cls: 0.1462  loss_box_reg: 0.1877  loss_mask: 0.2368  loss_rpn_cls: 0.01505  loss_rpn_loc: 0.03993  time: 0.3497  data_time: 0.0055  lr: 0.0014974  max_mem: 2365M\n","\u001b[32m[01/29 18:49:28 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 439  total_loss: 0.5942  loss_cls: 0.1257  loss_box_reg: 0.1698  loss_mask: 0.1924  loss_rpn_cls: 0.01981  loss_rpn_loc: 0.03062  time: 0.3464  data_time: 0.0051  lr: 0.0015688  max_mem: 2365M\n","\u001b[32m[01/29 18:49:34 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 459  total_loss: 0.5979  loss_cls: 0.1285  loss_box_reg: 0.1674  loss_mask: 0.1948  loss_rpn_cls: 0.01014  loss_rpn_loc: 0.02279  time: 0.3436  data_time: 0.0050  lr: 0.0016401  max_mem: 2397M\n","\u001b[32m[01/29 18:49:39 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 479  total_loss: 0.5379  loss_cls: 0.114  loss_box_reg: 0.1394  loss_mask: 0.1908  loss_rpn_cls: 0.01096  loss_rpn_loc: 0.02459  time: 0.3401  data_time: 0.0053  lr: 0.0017115  max_mem: 2397M\n","\u001b[32m[01/29 18:49:45 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 499  total_loss: 0.6595  loss_cls: 0.133  loss_box_reg: 0.1705  loss_mask: 0.2332  loss_rpn_cls: 0.0173  loss_rpn_loc: 0.07264  time: 0.3374  data_time: 0.0050  lr: 0.0017829  max_mem: 2397M\n","\u001b[32m[01/29 18:49:50 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 519  total_loss: 0.5978  loss_cls: 0.1248  loss_box_reg: 0.1418  loss_mask: 0.2134  loss_rpn_cls: 0.01089  loss_rpn_loc: 0.0539  time: 0.3351  data_time: 0.0053  lr: 0.0018542  max_mem: 2397M\n","\u001b[32m[01/29 18:49:56 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 539  total_loss: 0.7221  loss_cls: 0.1313  loss_box_reg: 0.1578  loss_mask: 0.199  loss_rpn_cls: 0.01672  loss_rpn_loc: 0.04447  time: 0.3328  data_time: 0.0054  lr: 0.0019256  max_mem: 2397M\n","\u001b[32m[01/29 18:50:01 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 559  total_loss: 0.5667  loss_cls: 0.114  loss_box_reg: 0.1464  loss_mask: 0.2006  loss_rpn_cls: 0.01149  loss_rpn_loc: 0.03658  time: 0.3307  data_time: 0.0051  lr: 0.0019969  max_mem: 2397M\n","\u001b[32m[01/29 18:50:07 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 579  total_loss: 0.5139  loss_cls: 0.1232  loss_box_reg: 0.155  loss_mask: 0.1977  loss_rpn_cls: 0.01192  loss_rpn_loc: 0.02883  time: 0.3287  data_time: 0.0050  lr: 0.0020683  max_mem: 2397M\n","\u001b[32m[01/29 18:50:12 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 599  total_loss: 0.518  loss_cls: 0.1089  loss_box_reg: 0.1734  loss_mask: 0.1936  loss_rpn_cls: 0.01044  loss_rpn_loc: 0.03306  time: 0.3267  data_time: 0.0054  lr: 0.0021396  max_mem: 2397M\n","\u001b[32m[01/29 18:50:17 d2.utils.events]: \u001b[0m eta: 0:00:22  iter: 619  total_loss: 0.5831  loss_cls: 0.1042  loss_box_reg: 0.1429  loss_mask: 0.1874  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.06729  time: 0.3250  data_time: 0.0054  lr: 0.002211  max_mem: 2397M\n","\u001b[32m[01/29 18:50:23 d2.utils.events]: \u001b[0m eta: 0:00:16  iter: 639  total_loss: 0.5045  loss_cls: 0.118  loss_box_reg: 0.1559  loss_mask: 0.1796  loss_rpn_cls: 0.01168  loss_rpn_loc: 0.02724  time: 0.3235  data_time: 0.0050  lr: 0.0022824  max_mem: 2397M\n","\u001b[32m[01/29 18:50:29 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 659  total_loss: 0.5878  loss_cls: 0.1159  loss_box_reg: 0.1603  loss_mask: 0.1989  loss_rpn_cls: 0.01407  loss_rpn_loc: 0.0677  time: 0.3221  data_time: 0.0052  lr: 0.0023537  max_mem: 2397M\n","\u001b[32m[01/29 18:50:34 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 679  total_loss: 0.4997  loss_cls: 0.1096  loss_box_reg: 0.1294  loss_mask: 0.1811  loss_rpn_cls: 0.008152  loss_rpn_loc: 0.03458  time: 0.3207  data_time: 0.0054  lr: 0.0024251  max_mem: 2397M\n","\u001b[32m[01/29 18:50:40 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 699  total_loss: 0.5303  loss_cls: 0.1099  loss_box_reg: 0.1625  loss_mask: 0.1965  loss_rpn_cls: 0.008955  loss_rpn_loc: 0.02434  time: 0.3195  data_time: 0.0052  lr: 0.0024964  max_mem: 2397M\n","\u001b[32m[01/29 18:50:40 d2.engine.hooks]: \u001b[0mOverall training speed: 698 iterations in 0:03:42 (0.3195 s / it)\n","\u001b[32m[01/29 18:50:40 d2.engine.hooks]: \u001b[0mTotal training time: 0:03:43 (0:00:00 on hooks)\n"]}]},{"cell_type":"code","metadata":{"id":"n5BPBa6Ld6Z8","executionInfo":{"status":"aborted","timestamp":1643481297990,"user_tz":-60,"elapsed":15,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}}},"source":["# Look at training curves in tensorboard:\n","%load_ext tensorboard\n","%tensorboard --logdir output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sNUMlT5IqlmY"},"source":["## Use model for inference\n","\n","Now, we can perform inference on our validation set by creating a predictor object."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1q6AI1_PoD9B","executionInfo":{"status":"ok","timestamp":1643482250752,"user_tz":-60,"elapsed":9640,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}},"outputId":"ad2ba965-4bc9-408e-ee81-be52e096fdf2"},"source":["# Evaluation\n","test_metadata = MetadataCatalog.get(\"my_dataset_valid\")\n","from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n","from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","\n","cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4\n","cfg.DATASETS.TEST = (\"my_dataset_valid\", )\n","predictor = DefaultPredictor(cfg)\n","evaluator = COCOEvaluator(\"my_dataset_valid\", cfg, False, output_dir=\"./output/\")\n","val_loader = build_detection_test_loader(cfg, \"my_dataset_valid\")\n","inference_on_dataset(trainer.model, val_loader, evaluator)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/29 18:50:41 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/29 18:50:42 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[01/29 18:50:42 d2.data.datasets.coco]: \u001b[0mLoaded 15 images in COCO format from /content/drive/MyDrive/Berlin DOP 2020 10cm SidesofRoad/Valid_annotations.json\n","\u001b[32m[01/29 18:50:42 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n","\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n","|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n","|  Ocluded   | 12           |  Parking   | 46           |  Possible  | 3            |\n","|            |              |            |              |            |              |\n","|   total    | 61           |            |              |            |              |\u001b[0m\n","\u001b[32m[01/29 18:50:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[01/29 18:50:42 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n","\u001b[32m[01/29 18:50:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n","\u001b[32m[01/29 18:50:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 batches\n","\u001b[32m[01/29 18:50:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. Dataloading: 0.2687 s/iter. Inference: 0.0602 s/iter. Eval: 0.0371 s/iter. Total: 0.3660 s/iter. ETA=0:00:01\n","\u001b[32m[01/29 18:50:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.928526 (0.392853 s / iter per device, on 1 devices)\n","\u001b[32m[01/29 18:50:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.061242 s / iter per device, on 1 devices)\n","\u001b[32m[01/29 18:50:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[01/29 18:50:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n","\u001b[32m[01/29 18:50:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","\u001b[32m[01/29 18:50:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n","\u001b[32m[01/29 18:50:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n","\u001b[32m[01/29 18:50:50 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[01/29 18:50:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.198\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.097\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.108\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.107\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.265\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.311\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.257\n","\u001b[32m[01/29 18:50:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 10.516 | 19.828 | 9.652  |  nan  | 10.780 | 10.694 |\n","\u001b[32m[01/29 18:50:50 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n","\u001b[32m[01/29 18:50:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n","| category   | AP     | category   | AP    | category   | AP    |\n","|:-----------|:-------|:-----------|:------|:-----------|:------|\n","| Ocluded    | 24.174 | Parking    | 7.375 | Possible   | 0.000 |\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","\u001b[32m[01/29 18:50:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n","\u001b[32m[01/29 18:50:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n","\u001b[32m[01/29 18:50:50 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[01/29 18:50:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.027\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.090\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.013\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.055\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.047\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.021\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.074\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.079\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.228\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.063\n","\u001b[32m[01/29 18:50:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n","|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n","|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n","| 2.706 | 9.005  | 1.280  |  nan  | 5.460 | 4.661 |\n","\u001b[32m[01/29 18:50:50 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n","\u001b[32m[01/29 18:50:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n","| category   | AP    | category   | AP    | category   | AP    |\n","|:-----------|:------|:-----------|:------|:-----------|:------|\n","| Ocluded    | 3.325 | Parking    | 4.792 | Possible   | 0.000 |\n"]},{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('bbox',\n","              {'AP': 10.516165542172205,\n","               'AP-Ocluded': 24.173875868417948,\n","               'AP-Parking': 7.374620758098673,\n","               'AP-Possible': 0.0,\n","               'AP50': 19.828103732097258,\n","               'AP75': 9.652432882169926,\n","               'APl': 10.693587896055618,\n","               'APm': 10.780019487196881,\n","               'APs': nan}),\n","             ('segm',\n","              {'AP': 2.705550553534839,\n","               'AP-Ocluded': 3.3248877682799334,\n","               'AP-Parking': 4.791763892324584,\n","               'AP-Possible': 0.0,\n","               'AP50': 9.005019671767922,\n","               'AP75': 1.2795327151762794,\n","               'APl': 4.66087487869666,\n","               'APm': 5.46009862184523,\n","               'APs': nan})])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"84yFQxKBQYrR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643482250754,"user_tz":-60,"elapsed":20,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}},"outputId":"b1bc494d-a5cf-4d3e-aeb0-b411c91608fd"},"source":["# Printing the names of the categories\n","for i, name in enumerate(MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes):\n","    print(i, name)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["0 Ocluded\n","1 Parking\n","2 Possible\n"]}]},{"cell_type":"code","metadata":{"id":"-M89OZOogAlF","executionInfo":{"status":"ok","timestamp":1643482250754,"user_tz":-60,"elapsed":11,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}}},"source":["# from detectron2.utils.visualizer import ColorMode\n","from skimage.measure import find_contours, approximate_polygon, subdivide_polygon\n","import glob\n","import json\n","import numpy as np\n","from pycocotools import mask\n","from skimage import measure\n","import base64\n","import cv2"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZPklT-zHSsKZ"},"source":["# Saving the predictions in lebelme format"]},{"cell_type":"code","metadata":{"id":"tkCmgDqrvAt7","executionInfo":{"status":"ok","timestamp":1643482626427,"user_tz":-60,"elapsed":21211,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}}},"source":["\n","for imageName in glob.glob('/content/drive/MyDrive/Berlin DOP 2020 10cm SidesofRoad/For matrices/*.jpeg'):\n","  \n","#for d in dataset_dicts:\n","  im = cv2.imread(imageName)\n","  outputs = predictor(im)\n","  masks = outputs['instances'].pred_masks.cpu().numpy()\n","  categories = outputs['instances'].pred_classes.cpu().numpy()\n","  encoded = base64.b64encode(open(imageName, \"rb\").read())\n","  number_of_masks = masks.shape[0]\n","  file_name_1 = imageName.replace(\"/content/drive/MyDrive/Berlin DOP 2020 10cm SidesofRoad/For matrices/\",\"\")\n","  file_name_2 = file_name_1.replace(\".jpeg\",\"\")\n","  file_name_3 = file_name_2 + \".json\"\n","  file_name_4 = str(\"/content/drive/MyDrive/Berlin DOP 2020 10cm SidesofRoad/New Folder/\") + str(file_name_3)\n","  #print(file_name_1, file_name_2, file_name_3, file_name_4)\n","  main_annotation = {}\n","  main_annotation['shapes'] = []\n","\n","\n","  # Iterating for all masks. Every mask has one contour and a category relevant for that\n","  for x in range(0, number_of_masks):\n","    # Selecting relevant mask. Number of masks == number of categories\n","    ground_truth_binary_mask = masks[x,:,:]\n","    category = categories[x]\n","    if category == 0:\n","      cat = \"Ocluded\"\n","    elif category == 1:\n","      cat = \"Parked\"\n","    else:\n","      cat = \"Possible\"\n","    #fortran_ground_truth_binary_mask = np.asfortranarray(ground_truth_binary_mask)\n","    #contours = measure.approximate_polygon(ground_truth_binary_mask, 0.5)\n","    contours = measure.find_contours(ground_truth_binary_mask, 0.5)\n","    try:\n","      app_con = measure.approximate_polygon(np.array(contours[0]), tolerance=0.8)\n","    except:\n","      continue\n","    annotation = {\n","          \"label\" : cat,\n","          #\"points\": np.flip(contours[0], axis=1).tolist(),\n","          \"points\": np.flip(app_con, axis=1).tolist(),\n","          \"group_id\": None,\n","          \"shape_type\": \"polygon\",\n","          \"flags\": {}}\n","\n","    main_annotation['shapes'].append(annotation)\n","\n","  main_annotation[\"imagePath\"] = file_name_1\n","  main_annotation[\"imageData\"] = str(encoded)[2:-1]\n","  main_annotation[\"imageHeight\"] = 512\n","  main_annotation[\"imageWidth\"] = 512\n","  #print(main_annotation)\n","  # print(json.dumps(annotation, indent=4,  separators=(',', ':',)))\n","  with open(file_name_4, 'w') as file:\n","    json.dump(main_annotation, file,indent=4,  separators=(',', ':',))\n","\n","  # v = Visualizer(im[:, :, ::-1],\n","  #                 metadata=test_metadata, \n","  #                 scale=1, \n","  #                 #instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n","  # )\n","  # v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","  # cv2_imshow(v.get_image()[:, :, ::-1])\n","\n","  # f = open(\"/content/drive/MyDrive/Cowc for detectrone2 test/COWC_PKLot_Predictions.txt\",\"a\")\n","  # f.write(str(d[\"file_name\"]) +\"\\n\" + str(outputs[\"instances\"])+\"\\n\")\n","  # f.close()\n","  # break\n","  # break"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l1AoosUHS4sb"},"source":["# Visualising the predictions"]},{"cell_type":"code","metadata":{"id":"OHPJWt33V0qT","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1NRSl0Sr-wsgW_bJw86wOIRVRsSP4n1jD"},"executionInfo":{"status":"ok","timestamp":1643482686985,"user_tz":-60,"elapsed":60566,"user":{"displayName":"Bashini Mahaarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvmkLemC5iG6WdL-cc2dNVZ3YLafkCfCaReo8bZA=s64","userId":"09965908729223653315"}},"outputId":"44ac5421-c999-4fb3-b980-d7bf8178ea2b"},"source":["from detectron2.utils.visualizer import ColorMode\n","import glob\n","\n","for imageName in random.sample(glob.glob('/content/drive/MyDrive/Berlin DOP 2020 10cm SidesofRoad/For matrices/*.jpeg'),15):\n","  im = cv2.imread(imageName)\n","  outputs = predictor(im)\n","  v = Visualizer(im[:, :, ::-1],\n","                metadata=test_metadata, \n","                scale=1\n","                 )\n","  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","  cv2_imshow(out.get_image()[:, :, ::-1])"],"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}